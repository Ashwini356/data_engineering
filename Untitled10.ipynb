{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM10yOuxJf/fc+5xhr9PLIO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashwini356/data_engineering/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KZ76nVWresN",
        "outputId": "383da33f-e6db-4b60-b138-f384a6af5b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 46 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 53.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=de48187d253b90386f4dce40ddb7c7af0fb992a96a8b9ce53bc9d312476d27b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "s8evASPtteiW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('pyspark').getOrCreate()"
      ],
      "metadata": {
        "id": "rakkRjO8t4Sz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_session():\n",
        "    spk = SparkSession.builder \\\n",
        "        .appName(\"Corona_cases_statewise.com\") \\\n",
        "        .getOrCreate()\n",
        "    return spk"
      ],
      "metadata": {
        "id": "PhdffF0Yu324"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_RDD(sc_obj, data):\n",
        "    df = sc.parallelize(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "7GApsh4CvSEx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " input_data = [(\"Uttar Pradesh\", 122000, 89600, 12238),\n",
        "                  (\"Maharashtra\", 454000, 380000, 67985),\n",
        "                  (\"Tamil Nadu\", 115000, 102000, 13933),\n",
        "                  (\"Karnataka\", 147000, 111000, 15306),\n",
        "                  (\"Kerala\", 153000, 124000, 5259)]"
      ],
      "metadata": {
        "id": "-v9agFkcuoJm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = create_session()"
      ],
      "metadata": {
        "id": "UgN9I9J_utnC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "nB09t617vBUa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd_df = create_RDD(sc, input_data)"
      ],
      "metadata": {
        "id": "rR8E18ytvITL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(type(rd_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iatSCCoLvZpz",
        "outputId": "41e4be51-91b4-4786-a67e-39a4b4796991"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.rdd.RDD'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['language','user_count']\n",
        "data = [('java','20000'),('python','100000'),('scala','3000')]"
      ],
      "metadata": {
        "id": "7F-GSjq6v-uq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "rdd=spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "aw4wW047wkAb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFromRDD1=rdd.toDF()\n",
        "dfFromRDD1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuz--ACbxKja",
        "outputId": "563791f9-c354-4a9b-fb35-b73e7f3d2b23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['language','user_count']\n",
        "dfFromRDD1=rdd.toDF(columns)\n",
        "dfFromRDD1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1KweFwgxjkt",
        "outputId": "e38a38bb-caa7-4a2c-bbe6-d730944cce37"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- language: string (nullable = true)\n",
            " |-- user_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFromRDD2=spark.createDataFrame(rdd).toDF(*columns)"
      ],
      "metadata": {
        "id": "55TH0xLJyi6V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFromData2=spark.createDataFrame(data).toDF(*columns)"
      ],
      "metadata": {
        "id": "W8-RmJ0vyxwm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        " (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        " (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        " (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        " (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
        " ]\n"
      ],
      "metadata": {
        "id": "4vwCck4i2JT1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([ \\\n",
        " StructField(\"firstname\",StringType(),True), \\\n",
        " StructField(\"middlename\",StringType(),True ), \\\n",
        " StructField(\"lastname\",StringType(),True), \\\n",
        " StructField(\"id\", StringType(), True), \\\n",
        " StructField(\"gender\", StringType(), True), \\\n",
        " StructField(\"salary\", IntegerType(), True) \\\n",
        " ])\n"
      ],
      "metadata": {
        "id": "km7ZuKQZ2SDi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=data2,schema=schema)\n"
      ],
      "metadata": {
        "id": "7Le5A0O-2_2P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmOBnjVB3BKu",
        "outputId": "ccbdbad0-823f-4b81-bb39-87a6a11d30db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDQnSw4Z3CTd",
        "outputId": "8d74352d-73d7-44f6-b185-95b8867e3cae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}